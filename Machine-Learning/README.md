
# Supervised and Unsupervised Learning

![image](https://github.com/user-attachments/assets/2d04458d-01e5-45e5-9184-f95849f44488)

![image](https://github.com/user-attachments/assets/b20e883b-eab9-4c9e-a0dc-49dfabb945b3)


# Responsible AI

Seven principles for responsible AI:
1. AI should be socially beneficial.
2. AI should avoid creating or reinforcing unfair bias.
3. AI should be built and tested for safety. -  seeks to promote the safety—both bodily integrity and overall health of people and communities, as well as the security of places, systems, properties, and infrastructures from attack or disruption.
4. AI should be accountable to people. -  aims to respect people’s rights and independence. The principle aims to promote informed user consent, and it seeks to ensure that there is a path to report and redress misuse, unjust use, or malfunction.
5. AI should incorporate privacy design principles. - the aim is to protect the privacy and safety of both individuals and groups. It is also the goal of the principle to ensure that users have clear expectations of how data will be used, and that they feel informed and have the ability to give consent to that use.
6. AI should uphold high standards of scientific excellence. - seeks to advance the state of knowledge in AI. This means to follow scientifically rigorous approaches and ensure that feature claims are scientifically credible.
7. AI should be made available for uses that accord with these principles. - The principle aims for the widest availability and impact of our beneficial AI technologies, while discouraging harmful or abusive AI applications.
